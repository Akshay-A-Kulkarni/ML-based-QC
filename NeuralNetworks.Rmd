---
title: "Neural Networks"
author: "Shantam Gupta"
date: "May 13, 2018"
output:
   pdf_document:
    highlight: tango
    latex_engine: lualatex
    number_sections: yes
    toc: yes
---

# Installing the Package
```{r, echo=FALSE, warning=FALSE, message=FALSE}
#install.packages("neuralnet")
library(neuralnet)
library(nnet)
library(dplyr)
library(caret)
```

# Load the Data 
```{r, echo = F}
Train <- read.csv('lumos_training_set.csv')
Test <- read.csv('lumos_all_set.csv')

#remove repeated measurements and reshape the dataset
ind <- which(with( Train, (Train$PepSeq=="EYEATLEEC(Carbamidomethyl)C(Carbamidomethyl)AK" | Train$PepSeq=="TC(Carbamidomethyl)VADESHAGC(Carbamidomethyl)EK") ))
S0<-Train[-ind,]
S0<-S0[,-2]
Train<-S0
S0$PepSeq<- gsub("\\(Carbamidomethyl\\)","",S0$PepSeq)
S0 <- reshape(S0, idvar = "idfile", timevar = "PepSeq", direction = "wide")
RESPONSE<-c("GO")
S0 <- cbind(S0,RESPONSE)

ind <- which(with( Test, (Test$PepSeq=="EYEATLEEC(Carbamidomethyl)C(Carbamidomethyl)AK" | Test$PepSeq=="TC(Carbamidomethyl)VADESHAGC(Carbamidomethyl)EK") ))
Data0<-Test[-ind,]
Data0<-Data0[,-2]
Data0$PepSeq<- gsub("\\(Carbamidomethyl\\)","",Data0$PepSeq)
Data1 <- Data0[1:8 + rep(seq(0, nrow(Data0), by=100), each=8),]
Data1 <- reshape(Data1, idvar = "idfile", timevar = "PepSeq", direction = "wide")
RESPONSE<-c("NOGO")
Data <- cbind(Data1,RESPONSE)
```

# Preprocess the data: Normalize the data
```{r}
new_data <- rbind(S0,Data)
maxs <- apply(new_data %>% select(-c(idfile,RESPONSE)), 2, max) 
mins <- apply(new_data %>% select(-c(idfile,RESPONSE)), 2, min)

scaled_data <- as.data.frame(scale(new_data %>% select(-c(idfile,RESPONSE)), center = mins, scale = maxs - mins))
#scaled_data$RESPONSE <- ifelse(new_data$RESPONSE =="GO",1,0)
scaled_data$RESPONSE <- as.factor(new_data$RESPONSE)
#scaled_data$RESPONSE <- as.factor(scaled_data$RESPONSE)
scaled_data$idfile <- new_data$idfile

#select random ind for train and test 
set.seed(123)

## 75% of the sample size
smp_size <- floor(0.75 * nrow(scaled_data))

## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(scaled_data)), size = smp_size)


train <- scaled_data[train_ind,]
test <- scaled_data[-train_ind,]
```

#Building Neural Network

```{r results='hide'}
library(h2o)
#generate same set of random numbers (for reproducibility)
set.seed(121)

#launch h2o cluster
localH2O <- h2o.init(nthreads = -1)


#import r objects to h2o cloud
train_h2o <- as.h2o(train)
test_h2o <- as.h2o(test)
```

```{r echo= FALSE}
#disable progress bar for pdf output
h2o.no_progress()
```

```{r}
#build the mlp(multi layer perceptron) deep learning model using h2o
set.seed(100)

dl_model <- h2o.deeplearning(
  model_id="dl_model_first", 
  training_frame=train_h2o, 
  validation_frame = test_h2o,
  x= colnames(train_h2o[,1:48]),
  y= "RESPONSE",
  activation="Rectifier",  
  hidden=c(5,4), 
  stopping_metric="mean_per_class_error",
  stopping_tolerance=0.01,
  epochs=100        
)
```

```{r}
summary(dl_model)
```
The accuracy is 98.57% . The net could be optmizied further to improve the accuracy 

### Tuning the ANN
The simplest hyperparameter search method is a brute-force scan of the full Cartesian product of all combinations specified by a grid search. There are a lot of paramters to tune and due to limited computational capabilities we shall try to tune only some of them.
```{r,results='hide', eval=FALSE}
#hyperparamters to tune 
hyper_params <- list(
  hidden=list(c(32,32,32),c(50,200,50)),  # different architectures of hidden layer
  input_dropout_ratio=c(0,0.05),      # values for drop out
  rate=c(0.01,0.02),                  # the learning rae
  activation = c("Rectifier")   # activation functions
)

#grid search

grid <- h2o.grid(
  algorithm="deeplearning",
  grid_id="dl_grid",
  model_id="dl_model_first", 
  training_frame=train_h2o, 
  x= colnames(train_h2o[,1:12]),
  y= "label",
  stopping_metric="mean_per_class_error",
  hyper_params = hyper_params,
  epochs=1000,   
  stopping_tolerance=0.01,
  variable_importances=T    
)
```

```{r tidy= TRUE, eval=FALSE}
#sort the model in the grid in decreasing order of error 
grid <- h2o.getGrid("dl_grid",sort_by="err",decreasing=FALSE)
grid

#best model and its full set of parameters
grid@summary_table[1,]
best_dl_model <- h2o.getModel(grid@model_ids[[1]])
best_dl_model

print(h2o.performance(best_dl_model))

#storing the confusion matrix
best_dl_confusion <- as.data.frame(h2o.confusionMatrix(best_dl_model))

```

### Plotting  the model
```{r}
plot(dl_model,timesteps = "epochs",metric = "classification_error")
```

The training accuracy decreases with increase in epochs. However, this might lead to overfitting on training data and poor fit on the test data. 

### Predictons on test data
```{r warning=FALSE, error=FALSE, message=F}
dl_predict <- as.data.frame(h2o.predict(dl_model, test_h2o))
```

```{r}
h2o.varimp_plot(dl_model)
```

```{r echo = FALSE, results='hide'}
#shut down the cluster
h2o.shutdown() 
```